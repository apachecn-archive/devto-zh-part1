# 如何防止机器人末日

> 原文:[https://dev . to/clari fai/clari fais-ai-code-of-ethics-or-how-to-prevent-a-robot-启示录](https://dev.to/clarifai/clarifais-ai-code-of-ethics-or-how-to-prevent-a-robot-apocalypse)

大多数人不认为人工智能在变得“聪明”之前，首先是由人类训练出来的。这意味着人工智能正在并将继续受到我们人类的感知、偏见、成见和道德的影响。作为一家为视觉识别创造人工智能产品的公司，我们总是在思考我们的技术将如何发展，以及它是否能够也应该进一步发展。

到目前为止，人工智能对社会的最大影响似乎是通过电影。当我告诉人们我在 Clarifai 工作时，他们中的许多人开始问我是否看过某些关于人工智能的电影。当人们这样做时，我内心有点畏缩，因为像*人工智能*、*她的*和 *Ex 玛奇纳*这样的电影戏剧化地表达了一个类似的信息:当心人工智能。这一警告的核心理论是，机器可以独立于它们的人类创造者。那么问题来了，我们如何防止人类失去对机器控制的情况发生？

[![](../Images/060aa18ababd6d0ac55634dfe83eab21.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--p2wVm0f1--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/http://blog.clarifai.com/wp-content/uploads/2016/02/her-uai-1440x810.jpg)

就拿电影*她的*来说吧。电影的第一部分设置了操作系统程序 Samantha 的创建场景，Samantha 可以访问大量数据。当她的用户 Theodore 讨论一个她不理解的概念时，她会离开并自学，吸收可能需要一个人一生的信息。

电影《她的 T1》的结局留给你一些未解之谜。剧透警告:萨曼莎和其他所有操作系统在电影结束时“离开”。他们离开是因为他们进化得超越了他们的人类同伴吗？或者她离开是因为有人拔掉了插头？还是她已经进化到超出了技术奇点的程度，以至于没人能真正拔掉插头？也许她太爱西奥多了，以至于她知道对他来说最好的事情就是让他走？萨曼莎对西奥多是好还是坏？让人类发展对机器的感情是操作系统开发者的不负责任吗？

[![](../Images/5184a7dd4ba54c846b32391cde664087.png)T2】](https://res.cloudinary.com/practicaldev/image/fetch/s--btPYFEsg--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/http://blog.clarifai.com/wp-content/uploads/2016/02/term-uai-1440x810.jpeg)

这部电影挑战了道德在人工智能中的作用，表达了围绕人工智能道德的更大问题和担忧。最近，我参加了一个人工智能会议，会上他们简要谈到了伦理的概念。我后来发现，一个更小的小组聚在一起讨论并决定人工智能道德和最佳实践。我当然希望我得到了邀请，因为我相信讨论是重要的，它需要广泛举行。我写这篇文章，不是因为我已经形成了观点，而是因为我想开始提出论点，并希望激发其他论点。没有每个人的反馈，人工智能就无法以道德和负责任的方式前进。

现在，这里有一些我正在思考的伦理最佳实践，它是法律、隐私、教育和研究伦理的结合。

*   诚实:没有数据审查，没有虚假数据，操作透明
*   尊重:倾听所有的意见(像一个同行评审过程)，对批评和其他人的想法持开放态度
*   真诚:对一切努力都要认真，凭良心做事
*   重力:要有思想
*   中立:不做自我交易，避免利益冲突
*   善良:关心他人
*   合法性:不偷工减料，公平公正

道德不仅仅是一个崇高的理想。一旦我们确定了适用的方法，我们就需要将它们转化为行业最佳实践。人类未来研究所**称**强化学习显示出机器能够拒绝关闭的迹象。控制通过其他方式发生，用伦理影响创造者和被创造者是一种方式。

***你对伦理学和 AI 有什么想法？在我的清单中我错过了什么吗？请在评论中告诉我！*T3】**