# 小规模流处理 kata:线程池

> 原文:https://dev . to/tnurkiewicz/small-scale-stream-processing-kata-thread-pools

[又一次](http://www.nurkiewicz.com/2015/10/geecon-programming-contest-answers.html)我为[我的公司](http://www.4financeit.com)准备了一场 [GeeCON 2016](http://2016.geecon.org/) 的编程比赛。这一次的任务要求设计并有选择地实施一个满足以下要求的系统:

* * *

一个系统每秒传送大约一千个事件。每个`Event`至少有两个属性:

*   `clientId` -我们预计一个客户端每秒最多只有几个事件
*   `UUID` -全球唯一

消耗一个事件大约需要 10 毫秒。设计这样的流的消费者:

1.  允许实时处理事件
2.  与一个客户端相关的事件应该按顺序处理，也就是说，您不能并行处理同一个`clientId`的事件
3.  如果重复的`UUID`在 10 秒内出现，扔掉它。假设 10 秒钟后不会出现重复项

* * *

这些要求中很少有重要的细节:

1.  每秒 1000 个事件，消耗一个事件需要 10 ms。显然，我们需要至少 10 个并发的消费者，以便接近实时地消费。
2.  事件有自然聚合 ID ( `clientId`)。在一秒钟内，我们可以预期给定客户端的几个事件，我们不允许并发或无序地处理它们。
3.  我们必须以某种方式忽略重复的消息，最有可能的是记住过去 10 秒内所有唯一的 id。这样就有大约 1 万个`UUID`可以暂时保留。

在这篇文章中，我想通过几个正确的解决方案和一些失败的尝试来指导你。您还将学习如何用很少的精确指标来解决问题。

# [](#naive-sequential-processing)天真的顺序处理

让我们在迭代中解决这个问题。首先我们必须对 API 做一些假设。想象它是这样的:

```
interface EventStream {

    void consume(EventConsumer consumer);

}

@FunctionalInterface
interface EventConsumer {
    Event consume(Event event);
}

@Value
class Event {

    private final Instant created = Instant.now();
    private final int clientId;
    private final UUID uuid;

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

典型的基于推送的 API，类似 JMS。一个重要的注意事项是`EventConsumer`正在阻塞，这意味着它不会提供新的`Event`，直到前一个被`EventConsumer`消耗掉。这只是我做的一个假设，并没有彻底改变需求。这也是消息监听器在 JMS 中的工作方式。简单的实现只是附加一个监听器，大约需要 10 毫秒来完成:

```
class ClientProjection implements EventConsumer {

    @Override
    public Event consume(Event event) {
        Sleeper.randSleep(10, 1);
        return event;
    }

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

当然，在现实生活中，这个消费者会在数据库中存储一些东西，进行远程调用等。我给睡眠时间分布添加了一点随机性，以使手动测试更加真实:

```
class Sleeper {

    private static final Random RANDOM = new Random();

    static void randSleep(double mean, double stdDev) {
        final double micros = 1_000 * (mean + RANDOM.nextGaussian() * stdDev);
        try {
            TimeUnit.MICROSECONDS.sleep((long) micros);
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
    }

}

//...

EventStream es = new EventStream();  //some real implementation here
es.consume(new ClientProjection()); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

它编译并运行，但是为了指出需求没有被满足，我们必须插入一些度量标准。最重要的指标是消息消耗的延迟，以消息创建和处理开始之间的时间来衡量。为此，我们将使用 [Dropwizard 指标](http://metrics.dropwizard.io/3.1.0/):

```
class ClientProjection implements EventConsumer {

    private final ProjectionMetrics metrics;

    ClientProjection(ProjectionMetrics metrics) {
        this.metrics = metrics;
    }

    @Override
    public Event consume(Event event) {
        metrics.latency(Duration.between(event.getCreated(), Instant.now()));
        Sleeper.randSleep(10, 1);
        return event;
    }

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

提取了`ProjectionMetrics`类来分离职责:

```
import com.codahale.metrics.Histogram;
import com.codahale.metrics.MetricRegistry;
import com.codahale.metrics.Slf4jReporter;
import lombok.extern.slf4j.Slf4j;

import java.time.Duration;
import java.util.concurrent.TimeUnit;

@Slf4j
class ProjectionMetrics {

    private final Histogram latencyHist;

    ProjectionMetrics(MetricRegistry metricRegistry) {
        final Slf4jReporter reporter = Slf4jReporter.forRegistry(metricRegistry)
                .outputTo(log)
                .convertRatesTo(TimeUnit.SECONDS)
                .convertDurationsTo(TimeUnit.MILLISECONDS)
                .build();
        reporter.start(1, TimeUnit.SECONDS);
        latencyHist = metricRegistry.histogram(MetricRegistry.name(ProjectionMetrics.class, "latency"));
    }

    void latency(Duration duration) {
        latencyHist.update(duration.toMillis());
    }
} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

现在，当您运行简单的解决方案时，您会很快发现中值延迟和 99.9%的百分比会无限增长:

```
type=HISTOGRAM, [...] count=84,   min=0,  max=795,   mean=404.88540608274104, [...]
    median=414.0,   p75=602.0,   p95=753.0,   p98=783.0,   p99=795.0,   p999=795.0
type=HISTOGRAM, [...] count=182,  min=0,  max=1688,  mean=861.1706371990878,  [...]
    median=869.0,   p75=1285.0,  p95=1614.0,  p98=1659.0,  p99=1678.0,  p999=1688.0

[...30 seconds later...]

type=HISTOGRAM, [...] count=2947, min=14, max=26945, mean=15308.138585757424, [...]
    median=16150.0, p75=21915.0, p95=25978.0, p98=26556.0, p99=26670.0, p999=26945.0 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

30 秒后，我们的应用程序平均以 15 秒的延迟处理事件。不完全是*实时*。显然，缺乏并发性是原因。我们的`ClientProjection`事件消费者需要大约 10 毫秒来完成，因此它每秒可以处理多达 100 个事件，而我们需要更多的数量级。我们必须以某种方式扩展`ClientProjection`。而且我们连其他要求都没碰过！

# [](#naive-thread-pool)幼稚线程池

最明显的解决方案是从多个线程调用`EventConsumer`。最简单的方法是利用`ExecutorService`:

```
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

class NaivePool implements EventConsumer, Closeable {

    private final EventConsumer downstream;
    private final ExecutorService executorService;

    NaivePool(int size, EventConsumer downstream) {
        this.executorService = Executors.newFixedThreadPool(size);
        this.downstream = downstream;
    }

    @Override
    public Event consume(Event event) {
        executorService.submit(() -> downstream.consume(event));
        return event;
    }

    @Override
    public void close() throws IOException {
        executorService.shutdown();
    }
} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

我们在这里使用了一个 [*装饰器*模式](https://en.wikipedia.org/wiki/Decorator_pattern)。原来的`ClientProjection`，实现`EventConsumer`是正确的。然而，我们用另一个增加并发性的`EventConsumer`实现来包装它。这将允许我们在不改变`ClientProjection`本身的情况下构建复杂的行为。这种设计促进了:

*   松耦合:各种`EventConsumer`互不了解，可以自由组合
*   单一责任:每个人做一项工作，并委托给下一个组件
*   [开放/封闭原则](https://en.wikipedia.org/wiki/Open/closed_principle):我们可以改变系统的行为，而无需修改现有的实现。

开放/封闭原则通常是通过注入策略和模板方法模式来实现的。这里就更简单了。整个接线如下所示:

```
MetricRegistry metricRegistry =
        new MetricRegistry();
ProjectionMetrics metrics =
        new ProjectionMetrics(metricRegistry);
ClientProjection clientProjection =
        new ClientProjection(metrics);
NaivePool naivePool =
        new NaivePool(10, clientProjection);
EventStream es = new EventStream();
es.consume(naivePool); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

我们精心制作的指标显示，情况确实好得多:

```
type=HISToOGRAM, count=838, min=1, max=422, mean=38.80768197277468, [...]
    median=37.0, p75=45.0, p95=51.0, p98=52.0, p99=52.0, p999=422.0
type=HISTOGRAM, count=1814, min=1, max=281, mean=47.82642776789085, [...]
    median=51.0, p75=57.0, p95=61.0, p98=62.0, p99=63.0, p999=65.0

[...30 seconds later...]

type=HISTOGRAM, count=30564, min=5, max=3838, mean=364.2904915942238, [...]
    median=352.0, p75=496.0, p95=568.0, p98=574.0, p99=1251.0, p999=3531.0 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

然而，我们仍然看到更小规模的延迟增长，30 秒后的延迟达到 364 毫秒。它一直在增长，所以这个问题是系统性的。我们...需要...更多...度量标准。注意到`NaivePool`(你很快就会明白为什么它是*天真的*)正好有 10 个线程可以支配。这应该足够处理上千个事件，每个事件需要 10 毫秒来处理。实际上，我们需要一点额外的处理能力来避免垃圾收集后或小负载高峰期间的问题。为了证明线程池实际上是我们的瓶颈，最好监视它的内部队列。这需要做一点工作:

```
class NaivePool implements EventConsumer, Closeable {

    private final EventConsumer downstream;
    private final ExecutorService executorService;

    NaivePool(int size, EventConsumer downstream, MetricRegistry metricRegistry) {
        LinkedBlockingQueue<Runnable> queue = new LinkedBlockingQueue<>();
        String name = MetricRegistry.name(ProjectionMetrics.class, "queue");
        Gauge<Integer> gauge = queue::size;
        metricRegistry.register(name, gauge);
        this.executorService = 
                new ThreadPoolExecutor(
                        size, size, 0L, TimeUnit.MILLISECONDS, queue);
        this.downstream = downstream;
    }

    @Override
    public Event consume(Event event) {
        executorService.submit(() -> downstream.consume(event));
        return event;
    }

    @Override
    public void close() throws IOException {
        executorService.shutdown();
    }
} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

这里的想法是手动创建`ThreadPoolExecutor`，以便提供定制的`LinkedBlockingQueue`实例。我们可以稍后使用该队列来监控它的长度(参见: [ExecutorService - 10 提示和技巧](http://www.nurkiewicz.com/2014/11/executorservice-10-tips-and-tricks.html))。
`Gauge`会定期调用`queue::size`并向任何你需要的地方报告。指标证实线程池大小确实是个问题:

```
type=GAUGE, name=[...].queue, value=35
type=GAUGE, name=[...].queue, value=52

[...30 seconds later...]

type=GAUGE, name=[...].queue, value=601 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

持有未决任务的队列的不断增长的大小损害了延迟。将线程池大小从 10 增加到 20 最终报告了不错的结果，并且没有出现停顿。然而，我们仍然没有解决相同`clientId`事件的重复和防止并发修改的问题。

# [](#obscure-locking)模糊锁定

让我们从避免对同一个`clientId`的事件进行并发处理开始。如果两个事件一个接一个很快发生，并且都与同一个`clientId`相关，`NaivePool`将选择这两个事件并开始并发处理它们。首先，我们至少会通过为每个`clientId`设置一个`Lock`来发现这种情况:

```
@Slf4j
class FailOnConcurrentModification implements EventConsumer {

    private final ConcurrentMap<Integer, Lock> clientLocks = new ConcurrentHashMap<>();
    private final EventConsumer downstream;

    FailOnConcurrentModification(EventConsumer downstream) {
        this.downstream = downstream;
    }

    @Override
    public Event consume(Event event) {
        Lock lock = findClientLock(event);
        if (lock.tryLock()) {
            try {
                downstream.consume(event);
            } finally {
                lock.unlock();
            }
        } else {
            log.error("Client {} already being modified by another thread", event.getClientId());
        }
        return event;
    }

    private Lock findClientLock(Event event) {
        return clientLocks.computeIfAbsent(
                event.getClientId(),
                clientId -> new ReentrantLock());
    }

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

这绝对是走错方向了。复杂的程度令人难以承受，但是运行这段代码至少揭示了一个问题。事件处理管道如下所示，一个装饰器包装另一个:

```
ClientProjection clientProjection =
        new ClientProjection(new ProjectionMetrics(metricRegistry));
FailOnConcurrentModification failOnConcurrentModification =
        new FailOnConcurrentModification(clientProjection);
NaivePool naivePool =
        new NaivePool(10, failOnConcurrentModification, metricRegistry);
EventStream es = new EventStream();

es.consume(naivePool); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

偶尔会弹出错误消息，告诉我们其他线程已经在处理同一个`clientId`的事件。对于每个`clientId`,我们关联一个`Lock`,我们检查它是为了判断另一个线程此刻是否没有处理那个客户端。尽管情况变得很糟糕，但我们实际上非常接近一个残酷的解决方案。不要因为另一个线程已经在处理某个事件而无法获得`Lock`而失败，让我们等一会儿，希望`Lock`会被释放:

```
@Slf4j
class WaitOnConcurrentModification implements EventConsumer {

    private final ConcurrentMap<Integer, Lock> clientLocks = new ConcurrentHashMap<>();
    private final EventConsumer downstream;
    private final Timer lockWait;

    WaitOnConcurrentModification(EventConsumer downstream, MetricRegistry metricRegistry) {
        this.downstream = downstream;
        lockWait = metricRegistry.timer(MetricRegistry.name(WaitOnConcurrentModification.class, "lockWait"));
    }

    @Override
    public Event consume(Event event) {
        try {
            final Lock lock = findClientLock(event);
            final Timer.Context time = lockWait.time();
            try {
                final boolean locked = lock.tryLock(1, TimeUnit.SECONDS);
                time.stop();
                if(locked) {
                    downstream.consume(event);
                }
            } finally {
                lock.unlock();
            }
        } catch (InterruptedException e) {
            log.warn("Interrupted", e);
        }
        return event;
    }

    private Lock findClientLock(Event event) {
        return clientLocks.computeIfAbsent(
                event.getClientId(),
                clientId -> new ReentrantLock());
    }

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

想法很像。但是`tryLock()`没有失败，而是等待 1 秒，希望给定客户端的`Lock`将被释放。如果两个事件很快相继发生，一个将获得一个`Lock`并继续进行，而另一个将阻塞等待`unlock()`发生。

这段代码不仅非常复杂，而且很可能在许多细微的地方被破坏了。例如，如果同一个`clientId`的两个事件几乎同时发生，但很明显其中一个是先发生的，那会怎样？
两个事件将同时请求`Lock`，我们无法保证哪个事件将首先获得不公平的`Lock`，可能会无序地消耗事件。一定有更好的方法...

# [](#dedicated-threads)专用线程

让我们后退一步，深呼吸。你如何确保事情不会同时发生？
嗯，就用一根线吧！事实上，我们一开始就是这么做的，但是产量并不令人满意。但是我们不关心不同`clientId`的并发性，我们只需要确保具有相同`clientId`的事件总是由相同的线程处理！

也许你想到了创建从`clientId`到`Thread`的地图？嗯，这可能过于简单化了。我们将创建数千个线程，每个线程根据需求在大部分时间都是空闲的(对于给定的`clientId`，每秒钟只有很少的事件)。一个好的折衷方案是固定大小的线程池，每个线程负责一个众所周知的`clientId`子集。这样，两个不同的`clientId`可能会在同一个线程上结束，但同一个`clientId`将总是由同一个线程处理。如果同一个`clientId`的两个事件出现，它们都将被路由到同一个线程，从而避免并发处理。实现简单得令人尴尬:

```
class SmartPool implements EventConsumer, Closeable {

    private final List<ExecutorService> threadPools;
    private final EventConsumer downstream;

    SmartPool(int size, EventConsumer downstream, MetricRegistry metricRegistry) {
        this.downstream = downstream;
        List<ExecutorService> list = IntStream
                .range(0, size)
                .mapToObj(i -> Executors.newSingleThreadExecutor())
                .collect(Collectors.toList());
        this.threadPools = new CopyOnWriteArrayList<>(list);
    }

    @Override
    public void close() throws IOException {
        threadPools.forEach(ExecutorService::shutdown);
    }

    @Override
    public Event consume(Event event) {
        final int threadIdx = event.getClientId() % threadPools.size();
        final ExecutorService executor = threadPools.get(threadIdx);
        executor.submit(() -> downstream.consume(event));
        return event;
    }
} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

最关键的部分就在最后:

```
int threadIdx = event.getClientId() % threadPools.size();
ExecutorService executor = threadPools.get(threadIdx); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

这个简单的算法将总是对同一个`clientId`使用同一个单线程`ExecutorService`。不同的 id 可能在同一个池中结束，例如当池大小为`20`、客户端`7`、`27`、`47`等时。将使用相同的线程。不过这也可以，只要一个`clientId`总是用同一个线程。此时，不需要锁定，并且保证了顺序调用，因为同一客户端的事件总是由同一线程执行。旁注:每个`clientId`一个线程是不可伸缩的，但是每个`clientId`一个角色(例如在 Akka 中)是一个很好的想法，可以简化很多。

顺便说一下，为了更加安全，我在每个线程池中插入了平均队列大小的指标，这使得实现时间更长:

```
class SmartPool implements EventConsumer, Closeable {

    private final List<LinkedBlockingQueue<Runnable>> queues;
    private final List<ExecutorService> threadPools;
    private final EventConsumer downstream;

    SmartPool(int size, EventConsumer downstream, MetricRegistry metricRegistry) {
        this.downstream = downstream;
        this.queues = IntStream
                .range(0, size)
                .mapToObj(i -> new LinkedBlockingQueue<Runnable>())
                .collect(Collectors.toList());
        List<ThreadPoolExecutor> list = queues
                .stream()
                .map(q -> new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, q))
                .collect(Collectors.toList());
        this.threadPools = new CopyOnWriteArrayList<>(list);
        metricRegistry.register(MetricRegistry.name(ProjectionMetrics.class, "queue"), (Gauge<Double>) this::averageQueueLength);
    }

    private double averageQueueLength() {
        double totalLength =
            queues
                .stream()
                .mapToDouble(LinkedBlockingQueue::size)
                .sum();
        return totalLength / queues.size();
    }

    //...

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

如果您有妄想症，您甚至可以为每个队列创建一个指标。

# [](#deduplication-and-idempotency)重复数据删除和幂等

在分布式环境中，当你的生产者至少有一次保证时，收到重复的事件是很常见的。这种行为背后的原因超出了本文的范围，但是我们必须学会如何面对这个问题。一种方法是将全局唯一标识符(`UUID`)附加到每条消息上，并确保在消费者端具有相同标识符的消息不会被处理两次。每个`Event`都有这样的`UUID`。根据我们的要求，最直接的解决方案是简单地存储所有见过的`UUID`，并在到达时验证收到的`UUID`以前从未见过。照原样使用`ConcurrentHashMap<UUID, UUID>`(JDK 没有`ConcurrentHashSet`)会导致内存泄漏，因为我们会随着时间的推移积累越来越多的 id。这就是为什么我们只在最后 10 秒寻找重复的。从技术上讲，您可以让`ConcurrentHashMap<UUID, Instant>`从`UUID`映射到遇到它时的时间戳。通过使用后台线程，我们可以删除超过 10 秒的元素。但是如果你是一个快乐的番石榴用户，`Cache<UUID, UUID>`用声明性驱逐策略将会达到目的:

```
import com.codahale.metrics.Gauge;
import com.codahale.metrics.Meter;
import com.codahale.metrics.MetricRegistry;
import com.google.common.cache.Cache;
import com.google.common.cache.CacheBuilder;

import java.util.UUID;
import java.util.concurrent.TimeUnit;

class IgnoreDuplicates implements EventConsumer {

    private final EventConsumer downstream;

    private Cache<UUID, UUID> seenUuids = CacheBuilder.newBuilder()
            .expireAfterWrite(10, TimeUnit.SECONDS)
            .build();

    IgnoreDuplicates(EventConsumer downstream) {
        this.downstream = downstream;
    }

    @Override
    public Event consume(Event event) {
        final UUID uuid = event.getUuid();
        if (seenUuids.asMap().putIfAbsent(uuid, uuid) == null) {
            return downstream.consume(event);
        } else {
            return event;
        }
    }
} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

再次强调，为了生产安全，我认为至少有两个指标可能有用:缓存大小和发现的重复项数量。让我们也插入这些指标:

```
class IgnoreDuplicates implements EventConsumer {

    private final EventConsumer downstream;
    private final Meter duplicates;

    private Cache<UUID, UUID> seenUuids = CacheBuilder.newBuilder()
            .expireAfterWrite(10, TimeUnit.SECONDS)
            .build();

    IgnoreDuplicates(EventConsumer downstream, MetricRegistry metricRegistry) {
        this.downstream = downstream;
        duplicates = metricRegistry.meter(MetricRegistry.name(IgnoreDuplicates.class, "duplicates"));
        metricRegistry.register(MetricRegistry.name(IgnoreDuplicates.class, "cacheSize"), (Gauge<Long>) seenUuids::size);
    }

    @Override
    public Event consume(Event event) {
        final UUID uuid = event.getUuid();
        if (seenUuids.asMap().putIfAbsent(uuid, uuid) == null) {
            return downstream.consume(event);
        } else {
            duplicates.mark();
            return event;
        }
    }
} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

最后，我们拥有了构建解决方案的所有要素。这个想法是由互相包装的`EventConsumer`实例组成管道:

1.  首先，我们应用`IgnoreDuplicates`来拒绝重复
2.  然后我们调用`SmartPool`,它总是将给定的`clientId`锁定到同一个线程，并在该线程中执行下一阶段
3.  最后`ClientProjection`被调用，执行真正的业务逻辑。

您可以选择在`SmartPool`和`ClientProjection`之间放置`FailOnConcurrentModification`步骤，以获得额外的安全性(设计上不应发生并发修改):

```
ClientProjection clientProjection =
        new ClientProjection(new ProjectionMetrics(metricRegistry));
FailOnConcurrentModification concurrentModification =
        new FailOnConcurrentModification(clientProjection);
SmartPool smartPool =
        new SmartPool(12, concurrentModification, metricRegistry);
IgnoreDuplicates withoutDuplicates =
        new IgnoreDuplicates(smartPool, metricRegistry);
EventStream es = new EventStream();
es.consume(withoutDuplicates); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

我们做了大量的工作来提出相对简单和结构良好的(我希望你同意)解决方案。最后，解决并发问题的最佳方法是...避免并发，并在一个线程中运行受竞争条件影响的代码。这也是 Akka actors(每个 actor 处理单个消息)和 RxJava(由`Subscriber`处理一个消息)背后的思想。

到目前为止，我们得到的是线程池和共享缓存的组合。这次我们将使用 RxJava 实现解决方案。首先，我从未透露过`EventStream`是如何实现的，只给出了 API:

```
interface EventStream {

    void consume(EventConsumer consumer);

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

事实上，对于手工测试，我构建了一个简单的 RxJava 流，其行为类似于需求中的系统:

```
@Slf4j
class EventStream {

    void consume(EventConsumer consumer) {
        observe()
            .subscribe(
                consumer::consume,
                e -> log.error("Error emitting event", e)
        );
    }

    Observable<Event> observe() {
        return Observable
                .interval(1, TimeUnit.MILLISECONDS)
                .delay(x -> Observable.timer(RandomUtils.nextInt(0, 1_000), TimeUnit.MICROSECONDS))
                .map(x -> new Event(RandomUtils.nextInt(1_000, 1_100), UUID.randomUUID()))
                .flatMap(this::occasionallyDuplicate, 100)
                .observeOn(Schedulers.io());
    }

    private Observable<Event> occasionallyDuplicate(Event x) {
        final Observable<Event> event = Observable.just(x);
        if (Math.random() >= 0.01) {
            return event;
        }
        final Observable<Event> duplicated =
                event.delay(RandomUtils.nextInt(10, 5_000), TimeUnit.MILLISECONDS);
        return event.concatWith(duplicated);
    }

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

理解这个模拟器是如何工作的并不重要，但是非常有趣。首先，我们生成稳定的`Long`值流(`0`、`1`、`2`...)每毫秒(每秒千个事件)使用`interval()`运算符。然后我们用`delay()`操作符在`0`和`1_000`微秒之间随机延迟每个事件。这样事件会出现在不太可预测的时刻，更真实一点的情况。最后，我们(使用 ekhem，`map()`运算符)将每个`Long`值映射到一个随机的`Event`，其中`clientId`位于`1_000`和`1_100`之间(包含-不包含)。

最后一点很有趣。我们想模拟偶尔的重复。为此，我们将每个事件(使用`flatMap()`)映射到其自身(在 99%的情况下)。然而，在 1%的情况下，我们返回该事件两次，其中第二次发生在 10 毫秒和 5 秒之后。在实践中，该事件的复制实例将出现在数百个其他事件之后，这使得流的行为非常真实。

有两种方式与`EventStream`交互——通过`consume()`基于回调和通过`observe()`基于流。我们可以利用`Observable<Event>`快速构建处理流水线，其功能与*第 1 部分*非常相似，但要简单得多。

# [](#missing-backpressure)背压缺失

第一种利用 RxJava 的天真方法很快就失败了:

```
EventStream es = new EventStream();
EventConsumer clientProjection = new ClientProjection(
        new ProjectionMetrics(
                new MetricRegistry()));

es.observe()
        .subscribe(
                clientProjection::consume,
                e -> log.error("Fatal error", e)
        ); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

(`ClientProjection`，`ProjectionMetrics` et。艾尔。出自[第一部](http://www.nurkiewicz.com/2016/10/small-scale-stream-processing-kata-part.html)。我们几乎在瞬间得到了`MissingBackpressureException`，这是意料之中的。还记得我们的第一个解决方案在处理事件时有多长的延迟吗？RxJava 试图避免这种情况，同时避免队列溢出。
`MissingBackpressureException`被抛出是因为消费者(`ClientProjection`)无法实时处理事件。这是*快速失效*行为。最快的解决方案是将消费转移到一个单独的线程池，就像以前一样，但是使用 RxJava 的工具:

```
EventStream es = new EventStream();
EventConsumer clientProjection = new FailOnConcurrentModification(
        new ClientProjection(
                new ProjectionMetrics(
                        new MetricRegistry())));

es.observe()
        .flatMap(e -> clientProjection.consume(e, Schedulers.io()))
        .window(1, TimeUnit.SECONDS)
        .flatMap(Observable::count)
        .subscribe(
                c -> log.info("Processed {} events/s", c),
                e -> log.error("Fatal error", e)
        ); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

`EventConsumer`接口有一个 helper 方法，可以在提供的`Scheduler`上异步使用事件:

```
@FunctionalInterface
interface EventConsumer {
    Event consume(Event event);

    default Observable<Event> consume(Event event, Scheduler scheduler) {
        return Observable
                .fromCallable(() -> this.consume(event))
                .subscribeOn(scheduler);
    }

} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

通过在单独的`Scheduler.io()`中使用`flatMap()`消费事件，每个消费都被异步调用。这一次，事件被近乎实时地处理，但是有一个更大的问题。我用`FailOnConcurrentModification`装饰`ClientProjection`是有原因的。事件相互独立地被消费，因此可能会发生同一`clientId`的两个事件被并发处理的情况。不太好。幸运的是，在 RxJava 中解决这个问题比普通线程容易得多:

```
es.observe()
        .groupBy(Event::getClientId)
        .flatMap(byClient -> byClient
                .observeOn(Schedulers.io())
                .map(clientProjection::consume))
        .window(1, TimeUnit.SECONDS)
        .flatMap(Observable::count)
        .subscribe(
                c -> log.info("Processed {} events/s", c),
                e -> log.error("Fatal error", e)
        ); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

一点点改变了。首先，我们按照`clientId`对事件进行分组。这将单个`Observable`流分割成*流*流。每个名为`byClient`的子流代表与同一个`clientId`相关的所有事件。现在，如果我们映射这个子流，我们可以确保与同一个`clientId`相关的事件不会被并发处理。外部流是懒惰的，所以我们必须订阅它。我们不是分别订阅每个事件，而是每秒收集事件并计数。这样，我们每秒接收一个类型为`Integer`的事件，表示每秒消耗的事件数。

# [](#impure-nonidiomatic-errorprone-unsafe-solution-of-deduplication-using-global-state)使用全局状态的重复数据删除的不纯、非惯用、易错、不安全的解决方案

现在我们必须删除重复的,`UUID` s。最简单，但非常愚蠢的删除重复的方法是利用全局状态。我们可以通过在`filter()`操作符之外的可用缓存中查找来简单地过滤掉重复项:

```
final Cache<UUID, UUID> seenUuids = CacheBuilder.newBuilder()
        .expireAfterWrite(10, TimeUnit.SECONDS)
        .build();

es.observe()
        .filter(e -> seenUuids.getIfPresent(e.getUuid()) == null)
        .doOnNext(e -> seenUuids.put(e.getUuid(), e.getUuid()))
        .subscribe(
                clientProjection::consume,
                e -> log.error("Fatal error", e)
        ); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

如果您想监控该机制的使用情况，只需添加 metric:

```
Meter duplicates = metricRegistry.meter("duplicates");

es.observe()
        .filter(e -> {
            if (seenUuids.getIfPresent(e.getUuid()) != null) {
                duplicates.mark();
                return false;
            } else {
                return true;
            }
        }) 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

从操作符内部访问全局状态，尤其是可变状态是非常危险的，并且破坏了 RxJava 的唯一目的——简化并发性。显然，我们使用了 Guava 的线程安全的`Cache`,但是在很多情况下，很容易遗漏从多个线程访问共享全局可变状态的地方。如果您发现自己在操作符链之外变异了一些变量，那么要非常小心。

# [](#custom-raw-distinct-endraw-operator-in-rxjava-1x)在 RxJava 1.x 中自定义`distinct()`运算符

RxJava 1.x 有一个`distinct()`操作符来完成这项工作:

```
es.observe()
        .distinct(Event::getUuid)
        .groupBy(Event::getClientId) 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

不幸的是，`distinct()`将所有的键(`UUID` s)存储在不断增长的`HashSet`中。但我们只关心最后 10 秒的重复！通过复制粘贴`DistinctOperator`的实现，我创建了`DistinctEvent`操作符，它利用番石榴的缓存只存储 UUID 最后 10 秒的值。我有意将`Event`硬编码到这个操作符中，而不是使它更通用，以使代码更容易理解:

```
class DistinctEvent implements Observable.Operator<Event, Event> {
    private final Duration duration;

    DistinctEvent(Duration duration) {
        this.duration = duration;
    }

    @Override
    public Subscriber<? super Event> call(Subscriber<? super Event> child) {
        return new Subscriber<Event>(child) {
            final Map<UUID, Boolean> keyMemory = CacheBuilder.newBuilder()
                    .expireAfterWrite(duration.toMillis(), TimeUnit.MILLISECONDS)
                    .<UUID, Boolean>build().asMap();

            @Override
            public void onNext(Event event) {
                if (keyMemory.put(event.getUuid(), true) == null) {
                    child.onNext(event);
                } else {
                    request(1);
                }
            }

            @Override
            public void onError(Throwable e) {
                child.onError(e);
            }

            @Override
            public void onCompleted() {
                child.onCompleted();
            }

        };
    }
} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

用法相当简单，整个实现(加上自定义操作符)如下所示:

```
es.observe()
        .lift(new DistinctEvent(Duration.ofSeconds(10)))
        .groupBy(Event::getClientId)
        .flatMap(byClient -> byClient
                .observeOn(Schedulers.io())
                .map(clientProjection::consume)
        )
        .window(1, TimeUnit.SECONDS)
        .flatMap(Observable::count)
        .subscribe(
                c -> log.info("Processed {} events/s", c),
                e -> log.error("Fatal error", e)
        ); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

实际上，如果您每秒跳过一次日志记录，它甚至会更短:

```
es.observe()
        .lift(new DistinctEvent(Duration.ofSeconds(10)))
        .groupBy(Event::getClientId)
        .flatMap(byClient -> byClient
                .observeOn(Schedulers.io())
                .map(clientProjection::consume)
        )
        .subscribe(
                e -> {},
                e -> log.error("Fatal error", e)
        ); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

这个解决方案比之前基于线程池和装饰器的解决方案要短得多。唯一尴尬的部分是自定义操作符，它避免了存储太多历史数据时的内存泄漏。

# [](#rxjava-2x-and-more-powerful-builtin-raw-distinct-endraw-)RxJava 2.x 和更强大的内置`distinct()`

实际上，我差*这*点就要向 RxJava 提交一个 PR 了，它实现了更强大的`distinct()`操作符。但是在我检查`2.x`分支之前，它是:`distinct()`允许提供定制`Collection`而不是硬编码`HashSet`。信不信由你，依赖倒置不仅仅是关于 Spring 框架或者 Java EE。当一个库允许你提供其内部数据结构的定制实现时，这也是 DI。首先我创建一个助手方法，它可以构建由`Cache<UUID, Boolean>`支持的`Map<UUID, Boolean>`支持的`Set<UUID>`。我们当然喜欢代表团！

```
private Set<UUID> recentUuids() {
    return Collections.newSetFromMap(
            CacheBuilder.newBuilder()
                    .expireAfterWrite(10, TimeUnit.SECONDS)
                    .<UUID, Boolean>build()
                    .asMap()
    );
} 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

有了这个方法，我们可以使用这个表达式来实现整个任务:

```
es.observe()
        .distinct(Event::getUuid, this::recentUuids)
        .groupBy(Event::getClientId)
        .flatMap(byClient -> byClient
                .observeOn(Schedulers.io())
                .map(clientProjection::consume)
        )
        .subscribe(
                e -> {},
                e -> log.error("Fatal error", e)
        ); 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

优雅，简单，清晰！它读起来几乎像一个问题:

*   观察一系列事件
*   只考虑不同的 UUIDs
*   按客户端分组事件
*   对于每个客户端，消费它们(按顺序)

希望您喜欢所有这些解决方案，并发现它们在您的日常工作中很有用。