# Lyft 微服务弹性特使入门

> 原文：<https://dev.to/kflynn/getting-started-with-lyft-envoy-for-microservices-resilience>

使用微服务解决现实世界的问题不仅仅是简单地写代码。你需要测试你的服务。您需要弄清楚如何进行持续部署。你需要找到干净、优雅、有弹性的方式让他们互相交流。

一个真正有趣的工具是 Lyft 的特使 T1，它可以帮助“互相交谈”。

## Lyft 特使概述

[Lyft Envoy](https://lyft.github.io/envoy/) 是一款现代化、高性能、小尺寸的 edge 和服务代理。Envoy 为您的服务增加了弹性和可观察性，并且它以一种对您的服务实现透明的方式做到了这一点。
看到我们叫出一个自称为[代理](https://softwareengineeringdaily.com/2017/02/14/service-proxying-with-matt-klein/)的东西，可能会感到奇怪——毕竟，外面有一大堆代理，800 磅的大猩猩是 [NGINX](http://nginx.org/en/) 和 [HAProxy](http://www.haproxy.org/) ，对吗？以下是关于特使的一些有趣之处:

*   它可以代理任何 TCP 协议。
*   它可以做 SSL。任何一个方向。
*   它使 HTTP/2 成为一等公民，可以在 HTTP/2 和 HTTP/1.1 之间转换(两个方向都可以)。
*   它在发现和负载平衡方面有很好的灵活性。
*   它旨在提高您系统的可见性。
    *   特别是，Envoy 可以生成大量的流量统计数据，否则很难获得这些数据。
    *   在某些情况下(比如 MongoDB 和 Amazon RDS ), Envoy 实际上知道如何查看有线协议并进行透明监控。
*   与其他一些游戏相比，这并不是一场噩梦。
*   这是一个附带的过程，所以它完全不依赖于服务的实现语言。

Envoy 在某些相当复杂的方面也是可扩展的，但我们将在稍后——可能是很久以后——深入探讨。现在我们要保持简单。(如果你对特使的更多细节感兴趣， [Matt Klein](https://thenewstack.io/lyfts-envoy-provides-move-monolith-soa/) 在 2017 年[微服务从业者峰会](https://www.microservices.com/summit/?__hstc=118178582.96cbe1ff6dfb8dbcb5a1e3c137e75cd5.1471276057845.1490817397765.1490888834051.194&__hssc=118178582.1.1490888834051&__hsfp=4034986108)上做了一个[的精彩演讲](https://www.microservices.com/talks/lyfts-envoy-monolith-service-mesh-matt-klein/?__hstc=118178582.96cbe1ff6dfb8dbcb5a1e3c137e75cd5.1471276057845.1490817397765.1490888834051.194&__hssc=118178582.1.1490888834051&__hsfp=4034986108)。)

能够代理任何 TCP 协议，包括使用 SSL，是一件大事。想代理 Websockets？Postgres？原始 TCP？去吧。还要注意，Envoy 既可以接受也可以发起 SSL 连接，这有时会很方便:您可以让 Envoy 进行客户端证书验证，但仍然有一个从 Envoy 到您的服务的 SSL 连接。

当然，HAProxy 也可以执行任意的 TCP 和 SSL 但它对 HTTP/2 所能做的只是将整个流转发到一个支持它的后端服务器。NGINX 不能执行任意协议(尽管公平地说，Envoy 不能执行 FastCGI，因为 Envoy 不是 web 服务器)。开源的 NGINX 和 HAProxy 都没有很好地处理服务发现(尽管 NGINX Plus 在这里有一些选项)。两者都没有一个适当配置的特使所拥有的相同的统计支持。

总的来说，我们发现 [Envoy 看起来很有前途](http://lethain.com/envoy-design/),能够只用一个软件支持我们的许多需求，而不需要混合搭配。

### 特使架构

虽然我说过，与我工作过的其他一些东西相比，Envoy 的设置没那么糟糕，但你会注意到，我并没有说它一定很容易。Envoy 的学习曲线一开始有点陡峭，看看为什么会有启发性。

### 特使与网络堆栈

假设你想写一个 HTTP 网络代理。有两种显而易见的方法:在 HTTP 级别工作，或者在 TCP 级别工作。

在 HTTP 级别，您可以离线读取整个 HTTP 请求，解析它，查看头部和 URL，然后决定做什么。然后，您将从后端读取整个响应，并将其发送给客户端。这是一个 OSI 第 7 层(*应用*)代理:代理完全知道用户到底想要完成什么，并且它开始使用这些知识来做非常聪明的事情。

缺点是复杂而缓慢——想想在做出任何决定之前读取和解析整个请求所带来的延迟吧！更糟糕的是，有时最高级别的协议根本没有您决策所需的信息。SSL 就是一个很好的例子:在添加 SRI 扩展之前，SSL 客户端永远不会声明它正在尝试连接到哪台主机——因此，尽管 HTTP 服务器可以很好地处理虚拟主机(使用 HTTP/1.1 `Host`报头),但是一旦涉及到 SSL，您就必须为您的服务器指定一个 IP 地址，因为第 7 层代理根本没有正确代理 SSL 所需的信息。

因此，也许更好的选择是在 TCP 层向下操作:只读写字节，使用 IP 地址、TCP 端口号等。来决定如何处理事情。这是一个 OSI 第三层(*网络*)或第四层(*传输*)代理，取决于你与谁交谈。我们将借用 Envoy 的术语，称之为第 3/4 层代理。

在这个模型中，事情可以非常快，某些事情变得非常优雅和简单(参见上面我们的 SSL 例子)。另一方面，假设您想将不同的 URL 代理到不同的后端？对于典型的 L3/4 代理来说，这是不可能的:更高级别的应用程序信息在这些层是不可访问的。

Envoy 处理了这样一个事实，即这两种方法同时在第 3、4 和 7 层工作，因而有实际的局限性。这是非常强大的，并且可以是非常高性能的…但是你通常以配置的复杂性为代价。

挑战在于让简单的事情变得简单，同时让复杂的事情变得可能，对于 HTTP 代理这样的事情，Envoy 做得相当好。

### 使节目

关于特使的下一点有点令人惊讶的是，大多数应用程序涉及两层特使，而不是一层:

*   首先，有一个“边缘特使”在某个地方独自运行。边缘使者的工作是给世界其他地方一个入口。来自外部的传入连接来到这里，边缘特使决定它们在内部去往何处。
*   第二，服务的每个实例都有它自己的特使在旁边运行，这是服务本身旁边的一个单独的进程。这些“服务使者”密切关注他们的服务，并记住哪些正在运行，哪些没有运行。
*   所有的代理形成一个网状网络，并在它们之间共享路由信息。
*   如果需要(通常是这样)，服务间调用也可以通过特使网格。我们稍后再讨论这个。

请注意，您当然可以只使用边缘代理，而不使用服务代理。然而，有了完整的网状网络，服务特使可以进行健康监控等，并让网状网络知道尝试联系停机服务是否毫无意义。此外，Envoy 的统计数据收集最适合全网格(更多信息请见另一篇文章)。

网格中的所有代理都运行相同的代码，但是它们的配置当然是不同的…这就把我们带到了代理配置文件。

### 特使配置概述

Envoy 的配置看起来很简单:它主要由*监听器*和*集群*组成。

一个*监听器*告诉特使一个它应该监听的 TCP *端口*，以及一组*过滤器*，特使应该用它们来处理它所听到的内容。一个*集群*告诉 Envoy 一个或多个后端*主机*，Envoy 可以将传入的请求代理到这些主机。到目前为止一切顺利。不过，事情变得不那么简单有两种主要方式:

*   过滤器可以——并且通常必须——拥有自己的配置，这通常比监听器的配置更复杂！
*   集群与负载平衡以及 DNS 等外部事物纠缠在一起。

既然我们已经讨论了 HTTP 代理，让我们继续看一看`http_connection_manager`过滤器。此过滤器在第 3/4 层运行，因此它可以访问来自 IP 和 TCP 的信息(如连接两端的主机和端口号)，但它也非常了解 HTTP 协议，可以访问 HTTP URL、报头等。，同时适用于 HTTP/1.1 和 HTTP/2。每当一个新的连接到达时，`http_connection_manager`使用所有这些信息来决定哪个 Envoy 集群最适合处理这个连接。然后，Envoy 集群使用其[负载平衡算法](http://blog.nobugware.com/post/2016/GRPC_Envoy_nghttp2_load_balancing/)挑选一个成员来处理 HTTP 连接。

`http_connection_manager`的过滤器配置是一个有相当多选项的字典，但目前对我们来说最关键的是`virtual_hosts`数组，它定义了过滤器将如何做出路由决定。数组中的每个元素都是包含以下属性的字典:

*   `name`:服务的可读名称
*   `domains`:DNS 风格的域名数组，其中一个必须与 URL 中的域名匹配，这样`virtual_host`才能匹配
*   `routes`:路由字典数组。

每个路由字典至少需要包括:

*   `prefix`:此路由的 URL 路径前缀
*   `cluster`:特使集群处理此请求
*   `timeout_ms`:出错放弃超时

所有这些意味着 HTTP 代理的最简单的情况——监听 HTTP 的指定端口，然后根据 URL 路由到不同的主机——实际上在 Envoy 中配置非常简单。

例如:要将以`/service1`开头的 URL 代理到名为`service1`的集群，并将以`/service2`开头的 URL 代理到名为`service2`的集群，可以使用:

```
“virtual_hosts”: [
  {
    “name”: “service”,
    “domains”: [“*”],
    “routes”: [
      {
        “timeout_ms”: 0,
        “prefix”: “/service1”,
        “cluster”: “service1”
      },
      {
        “timeout_ms”: 0,
        “prefix”: “/service2”,
        “cluster”: “service2”
      }
    ]
  }
] 
```

就是这样。注意，我们使用`domains [“*”]`来表示我们不太关心哪个主机被请求，还要注意，我们可以根据需要添加更多的路由。最后，这个监听器配置在 edge Envoy 和 service Envoy 之间基本上是相同的:主要区别在于 service Envoy 可能只有一个路由，并且它将只代理本地主机上的服务，而不是包含多个主机的集群。

当然，我们仍然需要定义上面的`virtual_hosts`部分中引用的`service1`和`service2`集群。我们在`cluster_manager`配置部分做这件事，它也是一个字典，也有一个关键组件，叫做`clusters`。它的值也是一个字典数组:

*   `name`:人类可读的集群名称
*   `type`:这个集群如何知道哪些主机在运行？
*   这个集群将如何处理负载平衡？
*   `hosts`:定义集群中主机的 URL 数组(实际上，通常是`tcp://`URL)。

`type`的可能值为:

*   `static`:集群中列出了所有可能的主机
*   特使将监控 DNS，每一个匹配的记录都将被认为是有效的
*   `logical_dns` : Envoy 基本上会使用 DNS 来添加主机，但如果 DNS 不再返回主机，就不会丢弃它们(想想有数百台主机的循环 DNS——我们将在后续文章中对此进行更多讨论)
*   `sds` : Envoy 将查询外部 REST 服务来查找集群成员

`lb_type`的可能值为:

*   `round_robin`:依次循环所有健康的主机
*   `weighted_least_reques` t:随机选择两个健康的主机，并挑选请求最少的一个(这是 O(1)，其中扫描所有健康的主机将是 O(n)。Lyft 声称，研究表明 O(1)算法“几乎和全扫描一样好”。)
*   随机选择一个主机

关于负载平衡有一个有趣的注意事项:集群还可以定义一个*紧急阈值*，如果集群中健康主机的数量低于紧急阈值，集群将决定健康检查算法被破坏，并假设集群中的所有主机都是健康的。这可能会导致惊喜，所以意识到这一点是有好处的！

边缘特使的一个简单例子可能是

```
“clusters”: [
  {
    “name”: “service1”,
    “type”: “strict_dns”,
    “lb_type”: “round_robin”,
    “hosts”: [
      {
        “url”: “tcp://service1:80”
      }
    ]
  },
  {
    “name”: “service2”,
    “type”: “strict_dns”,
    “lb_type”: “round_robin”,
    “hosts”: [
      {
        “url”: “tcp://service2:80”
      }
    ]
  }
] 
```

因为我们已经用类型`strict_dns`标记了这个集群，所以我们将依赖于在 DNS 中查找`service1`和`service2`，并且我们将假设任何新出现的服务实例都将被添加到 DNS 中——例如，这可能适合于使用`docker-compose`的设置。对于服务特使(比如说 T4)，我们可能会走一条更直接的路线:

```
“clusters”: [
  {
    “name”: “service1”,
    “type”: “static”,
    “lb_type”: “round_robin”,
    “hosts”: [
      {
        “url”: “tcp://127.0.0.1:5000”
      }
    ]
  }
] 
```

同样的想法，只是目标不同:我们总是在本地主机上使用我们的服务，而不是重定向到其他主机。

## 接下来

这是对特使的一万英尺的看法，再加上对特使的背景和配置的一点深入了解。接下来，我们将使用 Kubernetes、Postgres、Flask 和 Envoy 来实际部署一个简单的应用程序，并观察当我们对它进行缩放时，事情会如何发展。敬请关注。

## 对使节和微服感兴趣？

Datawire 团队一直在寻找能为我们基于 Envoy 的项目工作的人。如果你有兴趣加入我们的团队，[我们正在招聘](https://angel.co/datawire-io/jobs/265354-principal-software-engineer-envoy-oss)！

我们还发布了更多关于特使和微服务的文章，你可以在[微服务架构指南](https://www.datawire.io/guide/)中查看。

*本文最初是作为[微服务架构指南](https://www.datawire.io/guide/)的一部分发布的。*