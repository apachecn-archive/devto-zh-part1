# MongoDB 优化

> 原文:[https://dev.to/kyle_stratis/a-mongodb-optimization-e64](https://dev.to/kyle_stratis/a-mongodb-optimization-e64)

*原载于[我的个人博客](https://www.kylestratis.com/post/mongodb-aggregation-pipelines-to-reduce-time-of-data-operations)*

最近在 Homes.com，我的一个同事被指控加速一个批处理过程，我们被要求按预定的时间间隔运行。没什么大不了的，但是他被卡住了:这个过程在每个典型的“阶段”都需要很多步骤，用于识别我们需要提取的数据、提取数据、转换数据以及将转换后的数据写回 Mongo。当他谈到过程时，我意识到这将是 Mongo 聚合框架的一个完美用例。我主动提供帮助，基于我在工作于 [NASDANQ](https://nasdanq.com) 时获得的聚合框架的经验，并立即着手设计一个聚合管道来处理这个过程。

## 原解

这种批处理的存在是为了更新给定区域的平均和中值房屋价值数据。大致概述如下:

*   在大型集合(> 1 TB)中查询两个字段，这两个字段有助于标识属性所在的区域。
*   加入单个 ID
*   使用它从另一个数据库(> 25 GB)上的另一个集合中提取位置数据。
*   对于这个地区的每一处房产，我们从另一个集合中提取价格。
*   在我们的脚本中，这些被加载到一个数组中，然后我们迭代找到平均值和中值。

根据我们的估计，如果我们能够不间断地完成这个过程，大约需要 104 天才能完成。这是不可接受的，原因显而易见。

## 尝试第一次

我们在早期遇到了一个架构问题。MongoDB 的聚合管道不支持跨多个数据库工作，我们需要处理的集合被分散在几个数据库中。幸运的是，我们能够将集合转移到一个数据库上，这样我们就可以开始测试管道了。我们从一个 9 阶段的怪物开始——我们必须匹配的多个集合需要多个匹配阶段和一个执行本质上的连接的阶段。因为数据在每个阶段都存储在内存中，并且每个阶段的内存[都限制在 100 MB](https://docs.mongodb.com/manual/core/aggregation-pipeline-limits/)之内，所以我们首先尝试打开`allowDiskUse`选项，以允许管道至少运行。并运行它。我们的 DBA 团队通知我们，在管道运行时，内存使用量达到了不可接受的水平。

我们将管道简化为 7 个阶段——我们将位置数据作为管道的输入，将其与 25GB 集合进行匹配，使用`$lookup`加入 1TB 集合，在其中一个 ID 字段上保存 ID 字段，投影我们实际需要的字段，展开，编辑，按值排序，按位置分组(2 个字段)，取平均值，然后再次排序。管道看起来像这样:

```
$match->$lookup->$project->$unwind->$redact
                                      |
                                      V
       VALUES<-$sort<-$avg<-$group<-$sort 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

此操作在`$lookup`失败。为什么？对于许多地点，我们每个月都要加入近 100 万个文档的数据，并且我们需要这些数据的多年数据。在所有地点，这都无法解决我们的绩效问题。它也无法运行。

## 企图第二次

我们首先想到的是将唯一标识符(不同集合中两个字段的组合)添加到 1TB 集合中，但是由于集合的大小，这是不可行的。相反，我们可以做的是将我们用作 UID 的两个字段投影成一个串联版本，使用`$lookup`加入到 25GB 的集合中——因为对更小的集合进行这种更改要快得多。同时，我们测试了 ETL 代码中排序与管道本身中排序的性能差异。由于运行这些排序的代码花费的时间很少，我们可以从管道中删除这些阶段。现在，我们查看一个月中 10 天的所有 id，但是我们需要运行多年——这比原始解决方案的性能要差。

然而，一个有趣的发现是，当我们一次运行一个标识符时——一个月运行一个标识符大约需要一分钟。但是一个 3 年的位置识别器只用了 10 分钟。我提到这一点是因为它展示了聚合管道性能如何随着数据集的增长而良好地扩展。还记得我说过我们用 10 天的时间计划一个月的所有 id 吗？鉴于结果显示管道中花费的时间与数据大小不成线性比例，我们运行了管道并发现所有标识符的一个月花费了大约 14 个小时。这是一个很大的进步，但还不够。所以我们寻求更多的优化。

## 第三次尝试

这是一个较小的变化，但它本身在处理数据的时间上产生了巨大的变化。我们重新构建了我们的数据，这样我们就有了一个月数据的临时集合。我们通常一次处理一个月，不管我们想要多长时间。与之前的尝试相比，我们能够将时间减少一半——一个月的所有标识符现在只需要 7 个小时，而且我们现在不会查询完整的 1TB 集合，因为我们只需要其中的一小部分。创建临时集合很简单，由 DBA 团队中的同事作为数据加载过程的一部分来完成。

## 第四次尝试

看到这些结果后，管理层完全相信有必要重新设计我们存储这些数据的方式。让这成为一个教训:硬数据非常有说服力。因此，现在每个月的数据都将在自己的集合中，当我们加载数据时，位置数据也将被添加到这些每月的集合中，从而避免通过`$lookup`进行代价高昂的连接。令人惊讶的是，在测试时，添加这些信息并没有影响我们的总体数据预加载时间。这个位置数据也被索引以便更快地查询。所有这些让我们从 7 阶段聚合管道发展到 3 阶段。现在，我们从分割的集合开始，投影我们感兴趣的字段(位置、值等)。)，按位置分组，对它们进行平均，还将所有单个值添加到一个数组中(用于排序和查找代码中的中值)，并输出到一个临时集合。如果我们想处理一段时间超过一个月，我们冲洗和重复。

对于每个月的所有标识符，我们的处理时间从 7 小时增加到 8 分钟。然后，对生成的集合进行查询，以获得计算的平均值和单个值的数组，从而计算代码中的中值，如果我们串行执行，每个输出集合会增加一分钟。作为主要的 ETL 管道构建者，我们什么都不做。我们用 7 名工人进行了测试，增加的处理时间从 1 分钟到 30 秒不等。在生产过程中，我们有数百名工人，所以这额外的时间是令人满意的。如果我们保守地假设处理一个月的数据需要 7.5 分钟，那么预测 3 年后，我们估计应该会看到大约 4.5 小时的运行时间。我们决定我们对此感到满意，特别是当我们考虑到最初的过程预计需要 104 天的时候。

```
$project->$avg->$out 
```

<svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-on"><title>Enter fullscreen mode</title></svg> <svg width="20px" height="20px" viewBox="0 0 24 24" class="highlight-action crayons-icon highlight-action--fullscreen-off"><title>Exit fullscreen mode</title></svg>

## 结论

我从这个小项目中学到了很多东西，我想在这里把它们提炼出来作为一种 TL；博士保证它们可以传递给读者。

*   管理层被数据说服。运行您提议的更改，向他们展示性能改进的图表或数字。你们都在为同一个目标努力。
*   ABB。总是在建造。就我而言，我在 [NASDANQ](https://nasdanq.com) 上的工作给了我所需的知识，让我能够倾听队友的挣扎，识别用例，并实施计划来缓解这些问题。
*   单口相声很烂，但很有用。在一次站立会议上，我听到了我的队友与这些代码的斗争，这让我能够帮助他并提出一个可行的解决方案。
*   更一般地说，沟通很重要。不仅理解我的队友的需求是重要的，而且这个项目需要我们的 DBA 团队、我和我的队友(他们运行了我们的许多测试)之间的不断联系，以及我们团队、DBA 团队和我们报告的更大团队的管理。
*   最后，MongoDB 的聚合管道非常强大。如果您要处理相当大的数据集，那么它们是值得学习和熟悉的。