# 获得更多睡眠，一次一条亚马逊 SQS 信息

> 原文：<https://dev.to/sparkpost/getting-more-sleep-one-amazon-sqs-message-at-a-time>

## 我们为什么搬到亚马逊 SQS

SparkPost 的技术提供了全球超过 25%的非垃圾邮件。正如您所料，这意味着我们会生成大量数据。认真很多。在之前的一篇文章中，我描述了我们用来管理报告的堆栈。现在，我回来分享我们如何改进我们的分析和 webhook 基础架构，以实现更好的可扩展性和可靠性。

这对我们的客户和我们的运营团队都有好处。数学很简单:这些改进意味着我们的随叫随到的工程师需要更少的页面。页数越少=睡眠越多。更多的睡眠=更快乐的工程师。更快乐的工程师=更好的产品。请允许我更详细地解释一下为什么我们的随叫随到工程师会有更多的睡眠，以及我们是如何做到的。

去年年底，我们成功地用[亚马逊简单队列服务(SQS)](https://aws.amazon.com/sqs/) 取代了 RabbitMQ (RMQ)。这对你来说意味着什么？除了更可靠的服务，您应该不会看到我们的报告和分析功能的任何行为发生重大变化，包括我们的[消息事件 API](https://www.sparkpost.com/blog/category/feature/message-events/) 和指标报告。有几个小的例外:Webhook 批处理大小从最大 10K 减少到每批 100，抑制很快就会实时生效。

## RabbitMQ

RabbitMQ 是一个很棒的消息队列，但是我们使用它的方式不再满足我们的需要。我们堆栈中的这一块非常适合我们早期的内部软件。我们需要一个可扩展的报告系统，并且必须将数百万个事件转移到数据库中。我们还需要一个易于客户管理的架构，因此我们决定将 RMQ 尽可能靠近数据，这意味着与我们的 MTA 放在相同的服务器上。我们实现了[主题交换模式](https://www.rabbitmq.com/tutorials/tutorial-five-python.html)，并通过将关键字路由到交换来绑定队列。这很好，因为我们只发布了一次消息，但它被路由到 4 个不同的队列——度量、webhooks、消息事件和禁止显示。基于路由关键字，每个队列只得到数据的一个子集。

我们有各种业务需求，包括不丢失数据(惊喜，惊喜！)并且不传输相同的数据两次，所以我们必须坚持并且聪明地确保数据已经被处理。持久性意味着将数据持久地写入某个地方，在本例中是写入磁盘，这要求我们为 I/O 优化磁盘卷。

当我们开始建造 SparkPost 时，我们决定保留这个建筑，因为它在规模上对我们很有效。然而，我们很快发现，构建可伸缩的商业软件的好方法并不适用于管理大规模的服务。

我们遇到的一个问题是，当下游实体(数据库、webhook 消费者)的流量变得拥挤时，队列也会变得拥挤。这给我们的多边贸易协定带来了更高的风险，因为它们与 RMQ 共享资源。当数据不断流动时，持久队列工作得很好，但当 RMQ 备份时，它必须写入磁盘并从磁盘中拉出，这在 CPU、内存和 I/O 上产生了更多开销。在极端情况下，我们戴上消防员的帽子，努力确保我们不会丢失您的电子邮件或关于这些电子邮件的数据。没有人想经历这种高压力的过程，就像其他事情一样，它通常发生在奇怪的时间。我不会详细说明我们如何应对服务失败的风险，但这需要很多人对网络、nginx、ETLs、MTAs 等进行故障排除。我不能代表整个团队，但我想成为史蒂夫·温伍德那样的人，再次回到上流社会 …进入 SQS 和 Omni ETL:一个 ETL 统治他们所有人。

## Omni ETL

我们从使用 RMQ 和单独的 Node.js ETL 过程中学到了很多。它使得消息的批处理、转换、加载和确认(从消息队列中删除)变得容易，但是正如你在上面看到的，它也有一些缺点。我们调查了消息队列的替代方案，并在亚马逊 SQS 登陆。如果你经常阅读我们的博客，你会知道[我们都是关于 AWS](https://www.sparkpost.com/blog/aws-instead-data-center/) 的。SQS 名列前茅，但我们必须改变我们对这些数据的发布和订阅方式。以前，我们的事件软管一次一个地将事件记录到 RMQ 交换中，然后 ETL 读取它们并进行批处理和确认。为每个不同的流程读取和批处理数据时，会产生大量浪费的周期。

我们最终改变了批量处理消息的位置。现在不是在我们的 ETLs(消费者)中这样做，而是在事件软管(生产者)中这样做，它也在过帐到 SQS 之前压缩批次。由于消息的大小限制，需要对消息进行压缩，即 [256kb](http://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/limits-messages.html) 。我们从拥有独立的集群 node.js 流程发展到一个创建不同子流程的父流程，我们聪明的工程师 Jason Sorensen 恰当地将其命名为“Omni ETL”

我们需要一种技术来快速跟踪每个服务的状态，以便它可以确定何时可以从 SQS 队列中删除(用 RMQ 术语来说就是确认)消息。我们选择了带有 [redis 后端](https://redis.io/)的[elastic cache](https://aws.amazon.com/elasticache/)，我们现在真的很想看看我们还能在 SparkPost 中用它做什么。ElastiCache 只是一个围绕 redis 集群的托管服务，帮助我们按需扩展。那么这给我们带来了什么？

这个新架构有许多驱动因素；不仅仅是躲避即将发生的火灾。成本效率是一大驱动因素。我们必须用于 RMQ 分区的磁盘并不便宜，而且除了在高峰时期，它们没有得到充分利用。简化是另一个原因。当这项工作全面铺开后，node.js 进程的数量将减少 75%。它还使得在高峰期自动扩展更加容易，并具有更集中的监控和补救。最后，在应对我上面解释的队列备份相关问题时，我们不再让我们的 MTA 面临风险，因为 SQS 没有 RMQ 那样的副作用。

## 接下来是什么？

云优先是我们公司的核心价值观，Omni ETL 就是证明。我们能够在我们的架构中消除另一项自我管理的技术，这在我们的工程师睡觉时产生了回报。正如我们的首席执行官菲利普·梅里克最近所说，SparkPost 正在快速发展，我们的重点是大规模发送电子邮件。随着我们处理的电子邮件(和数据)量持续增长，对我们的堆栈进行的这些更改是关键的一步。这让我们的运营团队高枕无忧，并允许我们所有人继续提供新的可扩展解决方案。

我希望这已经揭示了 SparkPost 的内部结构，以及我们如何继续提供您需要的数据来改善您的电子邮件操作。我确实说过实时抑制即将到来，由于我们在 Omni ETL 中开始使用的技术，我们即将推出。敬请期待！如果你偶然看到这篇文章，并且不知道我们的报告功能、网页挂钩或抑制功能能做什么，[注册一个账户](https://pages.sparkpost.com/2016-Social-Bl-pricing.html?utm_source=blog&utm_medium=social-media&utm_campaign=dev&utm_content=lp-pricing&_ga=2.138991796.629230231.1494012498-302189911.1493655811)。用每月 100K 的免费邮件试驾一下吧。一如既往，来 SparkPost 社区 slack 和我们聊聊吧。

本帖最初由 **[SparkPost](https://www.sparkpost.com/blog/amazon-sqs/)** 发布。