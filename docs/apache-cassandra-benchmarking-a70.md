# Apache Cassandra 基准测试

> 原文：<https://dev.to/michaelmior/apache-cassandra-benchmarking-a70>

我最近试图在 [EC2](http://aws.amazon.com/ec2/) 上运行一些针对 [Apache Cassandra](http://cassandra.apache.org/) 的基准测试，因为不幸的是，我在机房的服务器在一场火灾中被毁。对于我所有的本地测试，我使用了一个运行在我的桌面计算机上的实例，但是我想为真正的基准测试做些准备，并使用三个节点。由于我的工作负载是只读的，数据集相当小，所以我还希望复制因子为 3，这样每个节点都有所有数据的副本。

我加载所有这些数据的第一次尝试是遵循 DataStax 提供的[一些文档](http://www.datastax.com/documentation/cql/3.0/cql/cql_using/update_ks_rf_t.html)。他们的建议是在 CQL 使用`ALTER KEYSPACE`来改变复制因子，然后在每个节点上简单地运行`nodetool repair`。但是，我发现对于中等大小的数据量(大约 2GB)，只在一个节点上运行修复需要几个小时。这是一个相当大的时间消耗，因为我希望能够快速上下旋转一个集群进行测试。

接下来，我尝试在导出数据之前在本地更改已配置的复制因子。然后，我简单地将数据复制到集群中的所有节点，并尝试正常启动它们。这造成了一些奇怪的冲突，因为节点似乎不清楚谁拥有哪部分数据。

最后，我简单地在单个节点上加载了数据集，并配置了复制因子 3。然后，我按顺序启动每个节点，自动引导过程负责将整个数据集复制到集群中的每个节点。整个过程不到半小时就完成了。这种方法在生产环境中实际上不起作用，因为它假设节点没有现有的数据(尽管如果您能够让一个节点离线一段时间，我认为它可能会起作用)。无论如何，这个解决方案对我来说非常有用，希望其他人也能发现它的用处。